:orphan:

Example gallery
===============

This gallery is intended to present examples on how to use scikit-maad to analyse audio recordings.
To run most of these examples you will need to download some samples from the :ref:`audio-dataset`.


.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. thumbnail-parent-div-close

.. raw:: html

    </div>

Basic examples
--------------


.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In audio signals, regions of interest are usually regions with high density of energy. The function find_rois_cwt allows finding regions of interest in the signal giving very simple and intuitive parameters: temporal length and frequency limits. This segmentation can be seen as a coarse detection process, the starting point of more advanced classification methods.">

.. only:: html

  .. image:: /_auto_examples/1_basic/images/thumb/sphx_glr_plot_find_rois_simple_thumb.png
    :alt:

  :ref:`sphx_glr__auto_examples_1_basic_plot_find_rois_simple.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Simple audio segmentation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="An audio signal can be represented in both, temporal and spectral domains.  These representations are complementary and fundamental to understand the audio signal characteristics. In this introductory example we will load an audio signal,  apply basic transformations to better understand its features in time and frequency.">

.. only:: html

  .. image:: /_auto_examples/1_basic/images/thumb/sphx_glr_plot_audio_representation_thumb.png
    :alt:

  :ref:`sphx_glr__auto_examples_1_basic_plot_audio_representation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Audio representation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="When dealing with large amounts of audio recordings, visualization plays a key role to evidence the main patterns in the data. In this example we show how to easily combine 96 audio  files to build a visual representation of a 24 hour natural soundscape.">

.. only:: html

  .. image:: /_auto_examples/1_basic/images/thumb/sphx_glr_plot_circadian_spectrogram_thumb.png
    :alt:

  :ref:`sphx_glr__auto_examples_1_basic_plot_circadian_spectrogram.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Circadian soundscape</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Template matching is a simple but powerfull method to detect a stereotyped sound of interest using a template signal. This example shows how to use the normalized cross-correlation of spectrograms. For a more detailed information on how to implement this technique in a large dataset check references [1,2].">

.. only:: html

  .. image:: /_auto_examples/1_basic/images/thumb/sphx_glr_plot_template_matching_example_thumb.png
    :alt:

  :ref:`sphx_glr__auto_examples_1_basic_plot_template_matching_example.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Template matching</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="When sound travels in air (or in water), initial acoustic signature may change  regarding distances due to attenuation. Sound attenuation in natural environment  is very complex to model. We propose to reduce the complexity by decomposing  the sound attenuation to three main sources of attenuation :  - the geometric attenuation (Ageo) also known as spreading loss or geometric  dispersion,  - the atmospheric attenuation (Aatm)  - and the habitat attenuation (Ahab). The later encompasses several sources of  attenuation and might be seen as a proxy.">

.. only:: html

  .. image:: /_auto_examples/1_basic/images/thumb/sphx_glr_plot_detection_distance_thumb.png
    :alt:

  :ref:`sphx_glr__auto_examples_1_basic_plot_detection_distance.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Detection distance estimation</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>

Advanced examples
-----------------


.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Acoustic fingerprinting is a technique that captures unique features of audio signals. For example, Shazam employs a spectrogram-based approach, converting audio into a visual representation and then identifying peaks on the spectrogram [1]. This fingerprint is matched against a vast database to identify the corresponding song. The method is robust in presence of noise, allowing accurate recognition of diverse audio sources in real-time. This approach is versatile, finding application in characterizing soundscapes. It has been successfully employed to evaluate FSC forest certification [2] and Neotropical oil palm landscapes [3].">

.. only:: html

  .. image:: /_auto_examples/2_advanced/images/thumb/sphx_glr_plot_graphical_soundscape_thumb.png
    :alt:

  :ref:`sphx_glr__auto_examples_2_advanced_plot_graphical_soundscape.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Acoustic fingerprinting and graphical soundscapes</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Soundscapes result from a combination of multiple signals that are mixed-down into a single time-series. Unmixing these signals can be regarded as an  important preprocessing step for further analyses of individual components. Here, we will combine the robust characterization capabilities of  the bidimensional wavelets [1] with an advanced signal decomposition tool, the  non-negative-matrix factorization (NMF)[2]. NMF is a widely used tool to analyse high-dimensional data that automatically extracts sparse and meaningfull components of non-negative matrices. Audio spectrograms are in essence sparse and  non-negative matrices, and hence well suited to be decomposed with NMF. This  decomposition can be further used to generate false-color spectrograms to  rapidly identify patterns in soundscapes and increase the interpretability of  the signal [3]. This example shows how to use scikit-maad to easily  decompose audio signals and visualize false-colour spectrograms.">

.. only:: html

  .. image:: /_auto_examples/2_advanced/images/thumb/sphx_glr_plot_nmf_and_false_color_spectrogram_thumb.png
    :alt:

  :ref:`sphx_glr__auto_examples_2_advanced_plot_nmf_and_false_color_spectrogram.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Signal decomposition and false-color spectrograms</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Unsupervised learning algorithms search for structures or patterns in a dataset without requiring labels. In the context of ecoacoustics, this approach can be usefull to draw inferences when manual labelling is inaccesible or too expensive. For example, unsupervised learning can be used to estimate the animal acoustic diversity [1], combine human-reasoning and automated procedures to build reference libraries, and find hidden structures in the soundscapes. ">

.. only:: html

  .. image:: /_auto_examples/2_advanced/images/thumb/sphx_glr_plot_unsupervised_sound_classification_thumb.png
    :alt:

  :ref:`sphx_glr__auto_examples_2_advanced_plot_unsupervised_sound_classification.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Classify soundtypes with unsupervised learning</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Environmental audio recordings usually have stationary noise that needs to be removed to enhance the signal to noise ratio of biological sounds. This example shows different ways to remove stationary background noise using spectral  subtraction techniques. These techniques are applied over the spectrogram and return a 2D matrix.  We use the sharpness metric to have a quantitative estimation of how well is the noise  reduction. For a more comprehensive analysis, other metrics should be use in complement.">

.. only:: html

  .. image:: /_auto_examples/2_advanced/images/thumb/sphx_glr_plot_remove_background_thumb.png
    :alt:

  :ref:`sphx_glr__auto_examples_2_advanced_plot_remove_background.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Remove background noise with signal processing tools</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="When sound travels in air (or in water), initial acoustic signature may change  regarding distances due to attenuation. Sound attenuation in natural environment  is very complex to model. We propose to reduce the complexity by decomposing  the sound attenuation to three main sources of attenuation :  - the geometric attenuation (Ageo) also known as spreading loss or geometric  dispersion,  - the atmospheric attenuation (Aatm)  - and the habitat attenuation (Ahab). The later encompasses several sources of  attenuation and might be seen as a proxy.">

.. only:: html

  .. image:: /_auto_examples/2_advanced/images/thumb/sphx_glr_plot_sound_degradation_due_to_attenuation_thumb.png
    :alt:

  :ref:`sphx_glr__auto_examples_2_advanced_plot_sound_degradation_due_to_attenuation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Simulation of sound degradation due to geometric, atmospheric and habitat attenuation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The goal of this example is to show how to download metadata from Xeno-Canto to infer species activities.  We focus on the activity of european woodpeckers.">

.. only:: html

  .. image:: /_auto_examples/2_advanced/images/thumb/sphx_glr_plot_xenocanto_woodpecker_activities_thumb.png
    :alt:

  :ref:`sphx_glr__auto_examples_2_advanced_plot_xenocanto_woodpecker_activities.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Download metadata from Xeno-Canto to infer species activities</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Sound pressure level (dB SPL) is a quantitative value that allows comparison of audio  recordings coming from different datasets and environments. Sound pressure level  corresponds to a quantitative measurement of the acoustic pressure energy.  An Automated Recording Unit (ARU) can be converted into a pseudo sound meter level  knowing few parameters: the sensitivity of the microphone, the amplification gain, the bit depth and the voltage range of the analog to digital converter. This is sufficient to convert a wav file (array of intergers) into pressure  (Pa). Of course, as the frequency response of the ARUs&#x27;s microphone is never flat,  the result is an approximation of the real sound pressure level. In order to be more precise, one should correct the frequency response of the microphone.">

.. only:: html

  .. image:: /_auto_examples/2_advanced/images/thumb/sphx_glr_plot_sound_pressure_level_thumb.png
    :alt:

  :ref:`sphx_glr__auto_examples_2_advanced_plot_sound_pressure_level.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Estimate sound pressure level from audio recordings</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Acoustic indices can summarize aspects of the acoustic energy distribution in audio recordings and are widely used to characterize animal acoustic communities[1-3]. In this example, we will see how to eficiently compute multiple acoustic indices,  and present basics post-processing posibilities. The audio recordings used in this  example can be downloaded from the open GitHub repository  (https://github.com/scikit-maad/scikit-maad/tree/production/data).">

.. only:: html

  .. image:: /_auto_examples/2_advanced/images/thumb/sphx_glr_plot_extract_alpha_indices_thumb.png
    :alt:

  :ref:`sphx_glr__auto_examples_2_advanced_plot_extract_alpha_indices.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Extract acoustic indices from audio recordings</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A spectrogram is a time-frequency (2d) representation of a audio recording.  Each acoustic event nested in the audio recording is represented by an acoustic signature. When sounds does not overlap in time and frequency, it is possible to extract automatically the acoustic signature as a region of interest (ROI)  by different image processing tools such as binarization, double thresholding, mathematical morphology tools...">

.. only:: html

  .. image:: /_auto_examples/2_advanced/images/thumb/sphx_glr_plot_compare_auto_and_manual_rois_selection_thumb.png
    :alt:

  :ref:`sphx_glr__auto_examples_2_advanced_plot_compare_auto_and_manual_rois_selection.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Find Regions of interest (ROIs) in a spectrogram</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Acoustic indices can summarize aspects of the acoustic energy distribution in audio recordings and are widely used to characterize animal acoustic communities[1-3]. In this example, we will see how to eficiently compute multiple acoustic indices,  and present basics post-processing posibilities. The audio recordings used in this  example can be downloaded from the open GitHub repository  (https://github.com/scikit-maad/scikit-maad/tree/production/data).">

.. only:: html

  .. image:: /_auto_examples/2_advanced/images/thumb/sphx_glr_extract_alpha_indices_multicpu_thumb.png
    :alt:

  :ref:`sphx_glr__auto_examples_2_advanced_extract_alpha_indices_multicpu.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Use multicpu functionality to compute indices</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Dependencies: To execute this example you need to have installed the  librosa, sklearn and pandas Python packages.">

.. only:: html

  .. image:: /_auto_examples/2_advanced/images/thumb/sphx_glr_plot_woodpecker_drumming_characteristics_thumb.png
    :alt:

  :ref:`sphx_glr__auto_examples_2_advanced_plot_woodpecker_drumming_characteristics.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Download audio files from Xeno-Canto and automatically extract characteristics</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


.. toctree::
   :hidden:
   :includehidden:


   /_auto_examples/1_basic/index.rst
   /_auto_examples/2_advanced/index.rst


.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-gallery

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download all examples in Python source code: _auto_examples_python.zip </_auto_examples/_auto_examples_python.zip>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download all examples in Jupyter notebooks: _auto_examples_jupyter.zip </_auto_examples/_auto_examples_jupyter.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
