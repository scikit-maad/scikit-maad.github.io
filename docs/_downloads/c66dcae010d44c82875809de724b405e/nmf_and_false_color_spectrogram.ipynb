{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nSource separation and false-colour spectrograms\n===============================================\n\nSoundscapes result from a combination of multiple signals that are mixed-down\ninto a single time-series. Unmixing these signals can be regarded as an \nimportant preprocessing step for further analyses of individual components.\nIn this example we will combine the robust characterization capabilities of \nthe ``shape_features`` with an advanced signal decomposition tool, the \nnon-negative-matrix factorization (NMF). NMF is a widely used tool to analyse\nhigh-dimensional that automatically extracts sparse and meaningfull components\nof non-negative matrices. Audio spectrograms are in essence sparse and \nnon-negative matrices, and hence well suited to be decomposed with NMF. This \ndecomposition can be further used to generate false-colour spectrograms to \nrapidly identify patterns in soundscapes. This example shows how to use the\nscikit-maad package to easily decompose audio signals and visualize \nfalse-colour spectrograms.\n\nDependencies: To execute this example you will need to have instaled the \nscikit-image and scikit-learn packages.\n\n@author: jsulloa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nfrom maad import sound, features\nfrom maad.util import linear2dB, plot2D\nfrom skimage import transform\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import NMF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load audio and compute a spectrogram\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s, fs = sound.load('../data/spinetail.wav')\nSxx, tn, fn, ext = sound.spectrogram(s, fs, nperseg=1024, noverlap=512)\n\nSxx_db = linear2dB(Sxx, db_range=80)\nSxx_db = transform.rescale(Sxx_db, 0.5, anti_aliasing=True, multichannel=False)\nplot2D(Sxx_db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute feature with shape_features_raw to get the raw output of the \nspectrogram filtered by the filterbank composed of 2D Gabor wavelets\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params, shape_im = features.shape_features_raw(Sxx_db, resolution='low')\n\n# Format the output as an array for decomposition\nX = np.array(shape_im).reshape([len(shape_im), Sxx_db.size]).transpose()\n\n# Decompose signal using non-negative matrix factorization\nY = NMF(n_components=3, init='random', random_state=0).fit_transform(X)\n\n# Format plt_data matrix\nY = MinMaxScaler(feature_range=(0,1)).fit_transform(Y)\nintensity = 1 - MinMaxScaler(feature_range=(0,0.99)).fit_transform(Sxx_db)\nplt_data = Y.reshape([Sxx_db.shape[0], Sxx_db.shape[1], 3])\nplt_data = np.dstack((plt_data, intensity))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the resulting basis spectrogram as separate elements and combine them to \nproduce a false-colour spectrogram\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot each basis spectrogram\nfig, axes = plt.subplots(3,1)\nfor idx, ax in enumerate(axes):\n    ax.imshow(plt_data[:,:,idx], origin='lower', aspect='auto', \n              interpolation='bilinear')\n    ax.set_axis_off()\n    ax.set_title('Basis ' + str(idx+1))\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first basis spectrogram shows fine and rapid modulations that the signal\nhas. Both signals have these features and hence both are delineated in this\nbasis. The second basis highlights the short calls on the background. The \nthird component highlights the longer vocalizations of the spinetail. \nThe three components can be mixed up to compose a false-colour spectrogram\nwhere it can be easily distinguished the different sound sources by color.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot a false-colour spectrogram\nfig, ax = plt.subplots(2,1)\nax[0].imshow(Sxx_db, origin='lower', aspect='auto', interpolation='bilinear', cmap='gray')\nax[1].imshow(plt_data, origin='lower', aspect='auto', interpolation='bilinear')\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}